{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Importando as bibliotecas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Inicializando o Foundation Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 256 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Carregando os modelos***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega uma lista com o nome de todos os modelos que foram treinados na etapa 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./model/lora_model_parte_1', './model/lora_model_parte_2', './model/lora_model_parte_3', './model/lora_model_parte_4', './model/lora_model_parte_5', './model/lora_model_parte_6', './model/lora_model_parte_7', './model/lora_model_parte_8', './model/lora_model_parte_9', './model/lora_model_final']\n"
     ]
    }
   ],
   "source": [
    "# Lista com os nomes dos arquivos\n",
    "modelos = [f'./model/lora_model_parte_{num}' for num in range(1, 10)]\n",
    "modelos.append('./model/lora_model_final')\n",
    "print(modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Carregando o dataset de teste***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega o dataset que ser√° utilizado para a avalia√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45c588b4f004d14b741a55c0cec5866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uid': ['B003YI166W', 'B0014DU2QY', 'B00523JL5K', 'B000AOEPMK', '0764599100'], 'title': ['Dreambaby Refrigerator Latch', 'Pacon Classroom Select Pacon Sentence Strip, 3 X 24 in, 1-1/2 in Ruling, 3/4 in Dotted Midline, 1 in Descender Space, Assorted Colors, Pack of 100', 'HTC EVO 3D Accessory - Blossoming Purple Violet Flower Protective Hard Case Cover Design for Sprint 4G', 'The Martha Stewart Holiday Collection - Homemade Holidays', 'Card Games For Dummies'], 'content': ['The Dream Baby Refrigerator Latch helps prevent children from opening fridges or freezers.', 'Pacon Classroom Select Assorted Super Bright Sentence Strip measuring 3 in x 24 in contains 1-1/2 in blue ruling, 3/4 in dotted midline and 1 in descender space. Strip is sold as 100 per pack.', 'Protect your cell phone with our premium Crystal Image case. This accessory provides protection for your cell phone from unnecessary scratch, dent or chips. It is made to fit perfectly and give the phone maximum protection. The hard strong plastic is reinforced from the front edge, side and back to prolong the life of your case. Beside its protection, it also has openings precisely made to access all the function of your phone. Transform your phone into a fashionable and distinctive device in seconds.', \"The Martha Stewart Holiday Collection: Homemade Holidaysis all about the art of making food and decorating for the Christmas or Hanukkah season. Woe be to anyone who views the four very diverse and remarkable Christmas dinner dishes here on an empty stomach: nothing will taste nearly as exciting. British chef Anne Willan drops by Stewart's kitchen to make a hearty, standing rib roast with accompanying Yorkshire pudding&#x97;foods she grew up eating in the farm country north of York. Chef Mario Batali, an expert on foods of Southern Italy, does two segments, one resulting in a fantastic seafood salad (with lobster, calamari, mussels, peppers, and more) and the other an impossibly beautiful baccala ravioli, using fresh-made pasta pillows filled with a mix of baccala and riced potatoes, tossed in Batali's red sauce with a hint of mint. Finally, chef Dan Silverman demonstrates how to remove pomegranate seeds from the fruit without too much hassle, and then add those seeds to an astonishing duck dish.Playful and dazzling desserts include meringue mushrooms, which look just like the real thing, and a Birch de Noel made of chocolate and cream, laid out like a Yuletide log. Household decorating hints are both clever and simple, including the strategic placing of colorful bowls of fruits and candies on shelves, and the embellishing of homemade wreaths with colorful balls (small, pink ones from Japan are oddly magical), candy, and popcorn. A section on Hanukkah gifts and foods includes a nice idea for filling embossed bags with candies, and a variation on traditional potato pancakes that includes adding strips of carrots and parsnips. Suggestions for making gifts and wrapping round out this very pleasant disc.--Tom Keogh\", \"Card Games for Dummiesbills itself as &quot;the fun and easy way  to play and win your favorite card games.&quot; The book is broken down into  different sections that broadly encompass the types of card games available: card-swapping  games (gin and rummy), trick-taking games (whist and euchre), games where you try to score as many points as possible (pinochle), and games where you don't want to score any points at all (hearts). Each chapter starts with the fundamentals--the definition of a &quot;trick,&quot; for example--and builds from there, progressing from the simplest games in each category to the more complex.Written by journalist Barry Rigal,Card Games for Dummiesis a nice companion piece to the more staidComplete Hoyle's Games. UnlikeHoyle's,Card Games for Dummiesnot only explains game mechanics, but gives you useful tips for play, provides the lowdown on strategy, and warns of the boneheaded blunders that you'd undoubtedly make if you'd been taught the rules and nothing more.So if you've always wanted to learn cribbage, but never wanted to ask a friend for a tutorial, this is the book for you. One word of warning: if you want to learn how to play bridge, you won't find much here other than a synopsis of the rules and a recommendation forBridge for Dummies.--Matthew Baldwin--This text refers to an out of print or unavailable edition of this title.\"], 'target_ind': [[42364, 103183, 159103, 182334, 182542, 220571, 220577, 315916, 331983, 397106, 430072, 445773, 452614, 502830, 546974, 564305, 594562, 599899, 697216], [78462, 116173, 137355, 153727, 156066, 211325, 347147, 353289, 353310], [614807, 614813, 614814, 614834, 616017, 616019, 616021, 620628, 622335, 982485, 1169309, 1169314, 1169317, 1169371, 1173610, 1173611, 1173613, 1173615, 1204801, 1218558, 1218559, 1218735, 1218747, 1219889, 1219890, 1219892], [657, 1480, 12456, 12460, 13498, 27633, 44405, 48604, 90716, 101444, 128517, 265584, 265585, 265619, 269221, 270732, 270820, 273898, 374154, 403646], [27292, 27293, 29894, 41573, 74017, 87302, 166143, 212685, 236339, 336634, 336638, 336639, 336649, 363062, 363064, 363637, 375901, 379731, 464633]], 'target_rel': [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]], 'text': ['Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nDreambaby Refrigerator Latch\\n\\n### Response:\\nThe Dream Baby Refrigerator Latch helps prevent children from opening fridges or freezers.</s>', 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nPacon Classroom Select Pacon Sentence Strip, 3 X 24 in, 1-1/2 in Ruling, 3/4 in Dotted Midline, 1 in Descender Space, Assorted Colors, Pack of 100\\n\\n### Response:\\nPacon Classroom Select Assorted Super Bright Sentence Strip measuring 3 in x 24 in contains 1-1/2 in blue ruling, 3/4 in dotted midline and 1 in descender space. Strip is sold as 100 per pack.</s>', 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nHTC EVO 3D Accessory - Blossoming Purple Violet Flower Protective Hard Case Cover Design for Sprint 4G\\n\\n### Response:\\nProtect your cell phone with our premium Crystal Image case. This accessory provides protection for your cell phone from unnecessary scratch, dent or chips. It is made to fit perfectly and give the phone maximum protection. The hard strong plastic is reinforced from the front edge, side and back to prolong the life of your case. Beside its protection, it also has openings precisely made to access all the function of your phone. Transform your phone into a fashionable and distinctive device in seconds.</s>', \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nThe Martha Stewart Holiday Collection - Homemade Holidays\\n\\n### Response:\\nThe Martha Stewart Holiday Collection: Homemade Holidaysis all about the art of making food and decorating for the Christmas or Hanukkah season. Woe be to anyone who views the four very diverse and remarkable Christmas dinner dishes here on an empty stomach: nothing will taste nearly as exciting. British chef Anne Willan drops by Stewart's kitchen to make a hearty, standing rib roast with accompanying Yorkshire pudding&#x97;foods she grew up eating in the farm country north of York. Chef Mario Batali, an expert on foods of Southern Italy, does two segments, one resulting in a fantastic seafood salad (with lobster, calamari, mussels, peppers, and more) and the other an impossibly beautiful baccala ravioli, using fresh-made pasta pillows filled with a mix of baccala and riced potatoes, tossed in Batali's red sauce with a hint of mint. Finally, chef Dan Silverman demonstrates how to remove pomegranate seeds from the fruit without too much hassle, and then add those seeds to an astonishing duck dish.Playful and dazzling desserts include meringue mushrooms, which look just like the real thing, and a Birch de Noel made of chocolate and cream, laid out like a Yuletide log. Household decorating hints are both clever and simple, including the strategic placing of colorful bowls of fruits and candies on shelves, and the embellishing of homemade wreaths with colorful balls (small, pink ones from Japan are oddly magical), candy, and popcorn. A section on Hanukkah gifts and foods includes a nice idea for filling embossed bags with candies, and a variation on traditional potato pancakes that includes adding strips of carrots and parsnips. Suggestions for making gifts and wrapping round out this very pleasant disc.--Tom Keogh</s>\", \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nCard Games For Dummies\\n\\n### Response:\\nCard Games for Dummiesbills itself as &quot;the fun and easy way  to play and win your favorite card games.&quot; The book is broken down into  different sections that broadly encompass the types of card games available: card-swapping  games (gin and rummy), trick-taking games (whist and euchre), games where you try to score as many points as possible (pinochle), and games where you don't want to score any points at all (hearts). Each chapter starts with the fundamentals--the definition of a &quot;trick,&quot; for example--and builds from there, progressing from the simplest games in each category to the more complex.Written by journalist Barry Rigal,Card Games for Dummiesis a nice companion piece to the more staidComplete Hoyle's Games. UnlikeHoyle's,Card Games for Dummiesnot only explains game mechanics, but gives you useful tips for play, provides the lowdown on strategy, and warns of the boneheaded blunders that you'd undoubtedly make if you'd been taught the rules and nothing more.So if you've always wanted to learn cribbage, but never wanted to ask a friend for a tutorial, this is the book for you. One word of warning: if you want to learn how to play bridge, you won't find much here other than a synopsis of the rules and a recommendation forBridge for Dummies.--Matthew Baldwin--This text refers to an out of print or unavailable edition of this title.</s>\"]}\n"
     ]
    }
   ],
   "source": [
    "# Caminho do arquivo JSON do dataset de teste\n",
    "caminho_arquivo = './LF-Amazon-1.3M/teste/tst_formatado.json'\n",
    "\n",
    "# Carregar o dataset diretamente do arquivo JSON\n",
    "dataset = load_dataset(\"json\", data_files=caminho_arquivo, split=\"train\")\n",
    "\n",
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Avaliando***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Argumentos de avalia√ß√£o**\n",
    "\n",
    "A √∫nica diferen√ßa √© a adi√ß√£o dos seguintes par√¢metros:\n",
    "- *do_train*: Desabilita o treinamento.\n",
    "- *do_eval*: Realiza a avalia√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√¢metros de avalia√ß√£o\n",
    "trainingArguments = TrainingArguments(\n",
    "    per_device_train_batch_size=128,\n",
    "    gradient_accumulation_steps=2,\n",
    "    warmup_steps=5,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=60,\n",
    "    learning_rate=3e-4,\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    logging_steps=20,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=3407,\n",
    "    output_dir=\"outputs\",\n",
    "    do_train=False,  # Desabilita o treinamento\n",
    "    do_eval=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fun√ß√£o de avalia√ß√£o**\n",
    "\n",
    "Realiza os seguintes passos:\n",
    "\n",
    "**1.** Limpeza de mem√≥ria\n",
    "- Realiza a limpeza da mem√≥ria antes de iniciar o modelo.\n",
    "\n",
    "**2.** Inicializa√ß√£o do modelo.\n",
    "- Inicia o modelo e o tokenizer passado por par√¢metro.\n",
    "\n",
    "**3.** Cria√ß√£o do *trainer*\n",
    "- Cria o trainer passando apenas o dataset de avalia√ß√£o.\n",
    "\n",
    "**4.** Avalia√ß√£o do modelo\n",
    "- Inicia a avaliaza√ß√£o do modelo com o dataset que foi passado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_e_limpar_memoria(modelo):\n",
    "    print(f\"Avaliando o modelo: {modelo}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()  # Limpar a mem√≥ria da GPU\n",
    "    gc.collect()  # For√ßar a coleta de lixo\n",
    "    \n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = modelo,\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    \n",
    "    # Configurar o treinador para cada parte do dataset\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        eval_dataset=dataset,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_num_proc=8,  # Multiprocessamento\n",
    "        packing=False,  # Se necess√°rio para sequ√™ncias curtas\n",
    "        args=trainingArguments\n",
    "    )\n",
    "    \n",
    "    # Avaliar o modelo\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Exibir os resultados da avalia√ß√£o\n",
    "    print(\"Resultados da Avalia√ß√£o:\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avalia√ß√£o**\n",
    "\n",
    "Para cada modelo √© realizado a avalia√ß√£o.\n",
    "\n",
    "Este notebook foi mais de curiosidade para saber como o modelo se comporta a cada parte do dataset treinado. Deu para ver os seguintes comportamentos no modelo com todo o dataset:\n",
    "\n",
    "- **Desempenho:** Apresentou uma perda de avalia√ß√£o mais baixa.\n",
    "- **Efici√™ncia:** Nas amostras e passos processados por segundo.\n",
    "- **Rapidez:** A avalia√ß√£o foi mais r√°pida mesmo tendo sido treinado com um volume maior de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando o modelo: ./model/lora_model_parte_1\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.8 patched 22 layers with 22 QKV layers, 22 O layers and 22 MLP layers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a41e03b5916452d81b0ee085b4134cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 41:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.5356433391571045, 'eval_model_preparation_time': 0.0047, 'eval_runtime': 2473.3637, 'eval_samples_per_second': 72.744, 'eval_steps_per_second': 9.093}\n",
      "Avaliando o modelo: ./model/lora_model_parte_2\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c39e60d924d444ea56668e224cfda4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 41:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.5052495002746582, 'eval_model_preparation_time': 0.0051, 'eval_runtime': 2492.5201, 'eval_samples_per_second': 72.185, 'eval_steps_per_second': 9.023}\n",
      "Avaliando o modelo: ./model/lora_model_parte_3\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c38d81b6ed7432e8b213e996f3b49eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 40:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.4845772981643677, 'eval_model_preparation_time': 0.0051, 'eval_runtime': 2450.2444, 'eval_samples_per_second': 73.43, 'eval_steps_per_second': 9.179}\n",
      "Avaliando o modelo: ./model/lora_model_parte_4\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b20a51a2094f6aa267c76e333ca66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 41:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.4691493511199951, 'eval_model_preparation_time': 0.0047, 'eval_runtime': 2477.7895, 'eval_samples_per_second': 72.614, 'eval_steps_per_second': 9.077}\n",
      "Avaliando o modelo: ./model/lora_model_parte_5\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa1845ba99744499bde60d6ac303278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 39:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.4564793109893799, 'eval_model_preparation_time': 0.0049, 'eval_runtime': 2375.8752, 'eval_samples_per_second': 75.729, 'eval_steps_per_second': 9.466}\n",
      "Avaliando o modelo: ./model/lora_model_parte_6\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d844d8ec354cb281ec2de8e9dd1323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 39:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.4462339878082275, 'eval_model_preparation_time': 0.0048, 'eval_runtime': 2394.4072, 'eval_samples_per_second': 75.143, 'eval_steps_per_second': 9.393}\n",
      "Avaliando o modelo: ./model/lora_model_parte_7\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcdc82a6a494de4b194e9ef10b66df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 40:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.4376862049102783, 'eval_model_preparation_time': 0.005, 'eval_runtime': 2406.5894, 'eval_samples_per_second': 74.762, 'eval_steps_per_second': 9.346}\n",
      "Avaliando o modelo: ./model/lora_model_parte_8\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8541cef185f4ff0887849dfef1e418c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 39:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.430120825767517, 'eval_model_preparation_time': 0.0078, 'eval_runtime': 2377.5417, 'eval_samples_per_second': 75.676, 'eval_steps_per_second': 9.46}\n",
      "Avaliando o modelo: ./model/lora_model_parte_9\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0838cb7d0a2464397be352d2107d4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 40:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.4238680601119995, 'eval_model_preparation_time': 0.0051, 'eval_runtime': 2446.0835, 'eval_samples_per_second': 73.555, 'eval_steps_per_second': 9.195}\n",
      "Avaliando o modelo: ./model/lora_model_final\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396f8f1087d042d9ac68dff77a6d8809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/179922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22491' max='22491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22491/22491 39:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da Avalia√ß√£o: {'eval_loss': 1.4180196523666382, 'eval_model_preparation_time': 0.005, 'eval_runtime': 2385.5828, 'eval_samples_per_second': 75.421, 'eval_steps_per_second': 9.428}\n",
      "Avalia√ß√£o conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "for _, modelo in enumerate(modelos):\n",
    "    avaliar_e_limpar_memoria(modelo)\n",
    "    \n",
    "print(\"Avalia√ß√£o conclu√≠do.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
