{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Importando as bibliotecas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Inicializando o Foundation Model***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Foundation Model escolhido para o treinamento ser√° o **unsloth/tinyllama-bnb-4bit** por conta do tamanho e a utiliza√ß√£o da mem√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 256 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/tinyllama-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Pr√©-processamento do dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt**\n",
    "\n",
    "Para estruturar os dados de treinamento vai ser utilizado o Alpaca, com isso vai ser poss√≠vel fornecer ao modelo uma estrutura consistente que vai incluir:\n",
    "- **Instru√ß√£o**\n",
    "- **Input (Contexto adicional)**\n",
    "- **Resposta esperada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fun√ß√µes de apoio**\n",
    "\n",
    "As fun√ß√µes abaixo ser√£o utilizadas para o pre-processamento do dataset, uma fun√ß√£o valida a quantidade de vazios dentro de um campo especifico e a outra vai formatar os dados do dataset para o prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica a quantidade de vazio em um campo espec√≠fico do dataset\n",
    "def contar_campos_vazios(dataset, campo):\n",
    "    qtd_vazio = 0\n",
    "\n",
    "    for example in dataset:\n",
    "        if not example[campo]:\n",
    "            qtd_vazio += 1\n",
    "\n",
    "    return qtd_vazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formata o dataset para o formato esperado pelo modelo\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"title\"]\n",
    "    outputs = examples[\"content\"]\n",
    "    texts = []\n",
    "    \n",
    "    for input, output in zip(inputs, outputs):       \n",
    "        instruction = \"Generate a detailed product description based on the following title:\"\n",
    "        \n",
    "        # Formata o prompt incluindo o token EOS ao final\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formatando o dataset**\n",
    "\n",
    "Para a formata√ß√£o ser√° utilizado as duas fun√ß√µes acima.\n",
    "\n",
    "Inicialmente ser√° validado quantos campos vazios existem na coluna 'content' e na coluna 'title' do dataset, depois ser√° removido esses vazios e finalmente ser√° realizado a formata√ß√£o dos dados e a cria√ß√£o de uma nova coluna chamada 'text' que vai conter o prompt que ser√° utilizado na avalia√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas com content vazio: 323121\n",
      "Linhas com title vazio: 55556\n"
     ]
    }
   ],
   "source": [
    "# Carrega o dataset completo.\n",
    "dataset = load_dataset(\"json\", data_files='./LF-Amazon-1.3M/teste/tst.json', split=\"train\")\n",
    "\n",
    "# Valida a quantidade de linhas com 'content' vazio\n",
    "qtd_vazio = contar_campos_vazios(dataset, 'content')\n",
    "print(f\"Linhas com content vazio: {qtd_vazio}\")\n",
    "\n",
    "# Valida a quantidade de linhas com 'title' vazio\n",
    "qtd_vazio = contar_campos_vazios(dataset, 'title')\n",
    "print(f\"Linhas com title vazio: {qtd_vazio}\")\n",
    "\n",
    "# Filtrar o dataset, removendo linhas com 'title' ou 'content' vazios\n",
    "dataset_processado = dataset.filter(lambda example: example[\"content\"] != \"\" and example[\"title\"] != \"\")\n",
    "\n",
    "# Agora que o dataset est√° limpo, vamos formatar os prompts\n",
    "dataset_formatado = dataset_processado.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Separando o dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar ser√° pego 30% do dataset de teste e de forma aleat√≥ria. \n",
    "\n",
    "Os 30% √© para que o tempo de avalia√ß√£o n√£o fique muito grande mas contenha uma quantidade razo√°vel de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando apenas 30% do meu dataset para avalia√ß√£o\n",
    "num_avaliacao = int(len(dataset_formatado) * 0.3)\n",
    "\n",
    "dataset_teste = dataset_formatado.shuffle(seed=42).select(range(num_avaliacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737fb4353a1c4d3a863da4371a2463df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/180 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "347026274"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar o dataset no formato JSON\n",
    "dataset_teste.to_json('./LF-Amazon-1.3M/teste/tst_formatado.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
