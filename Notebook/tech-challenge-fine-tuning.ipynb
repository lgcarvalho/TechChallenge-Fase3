{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1IADT - Tech Challenge - Fase 3**\n",
    "**Luiz Carvalho**\n",
    "\n",
    "**Grupo:** \n",
    "\n",
    "**GitHub:** \n",
    "\n",
    "**Youtube:** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O PROBLEMA**\n",
    "\n",
    "No Tech Challenge desta fase, você precisa executar o fine-tuning de um foundation model (Llama, BERT, MISTRAL etc.), utilizando o dataset \"[TheAmazonTitles-1.3M](https://drive.google.com/file/d/12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK/view)\". O modelo treinado deverá:\n",
    "- Receber perguntas com um contexto obtido por meio do arquivo json “trn.json” que está contido dentro do dataset.\n",
    "- A partir do prompt formado pela pergunta do usuário sobre o título do produto, o modelo deverá gerar uma resposta baseada na pergunta do usuário trazendo como resultado do aprendizado do fine-tuning os dados da sua descrição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FLUXO DE TRABALHO**\n",
    "\n",
    "1. **Escolha do Dataset:**\n",
    "\n",
    "   O The AmazonTitles-1.3MM consiste em consultas textuais reais de usuários e títulos associados de produtos relevantes encontrados na Amazon e suas descrições, medidos por ações implícitas ou explícitas dos usuários.\n",
    "\n",
    "2. **Preparação do Dataset:**\n",
    "\n",
    "   Faça o download do dataset [AmazonTitles-1.3M](https://drive.google.com/file/d/12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK/view) e utilize o arquivo “trn.json”. Nele, você utilizará as colunas “title” e “content”, que contêm título e descrição respectivamente. Prepare os prompts para o fine-tuning garantindo que estejam organizados de maneira adequada para o treinamento do modelo escolhido. Limpe e pré-processe os dados conforme necessário para o modelo escolhido.\n",
    "\n",
    "3. **Chamada do Foundation Model**\n",
    "\n",
    "   Importe o foundation model que será utilizado e faça um teste apresentando o resultado atual do modelo antes do treinamento (para que se obtenha uma base de análise após o fine-tuning), e então será possível avaliar a diferença do resultado gerado.\n",
    "\n",
    "4. **Execução do Fine-Tuning:**\n",
    "\n",
    "   Execute o fine-tuning do foundation model selecionado (por exemplo, BERT, GPT, Llama) utilizando o dataset preparado. Documente o processo de fine-tuning, incluindo os parâmetros utilizados e qualquer ajuste específico realizado no modelo.\n",
    "\n",
    "5. **Geração de Respostas:**\n",
    "\n",
    "   Configure o modelo treinado para receber perguntas dos usuários. O modelo deverá gerar uma resposta baseada na pergunta do usuário e nos dados provenientes do fine-tuning, incluindo as fontes fornecidas. O que esperamos para o entregável?\n",
    "   - Documento detalhando o processo de seleção e preparação do dataset.\n",
    "   - Descrição do processo de fine-tuning do modelo, com detalhes dos parâmetros e ajustes utilizados. Código-fonte do processo de finetuning.\n",
    "   - Um vídeo demonstrando o modelo treinado gerando respostas a partir de perguntas do usuário e utilizando o contexto obtido por meio treinamento com o fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ambiente**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o desenvolvimento foi utilizado o **VSCode** com o Kernel conectado em um **Jupyter Server** com **Unsloth**.\n",
    "\n",
    "O treinamento foi realizado em uma **RTX 4070 TI** com memória de **12GB**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Instalação das Biliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets # Biblioteca Hugging Face Datasets\n",
    "\n",
    "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
    "%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "%pip install --no-deps {xformers} trl peft accelerate bitsandbytes triton\n",
    "\n",
    "%pip install torch # Biblioteca PyTorch\n",
    "%pip install trl # Biblioteca TRL (Transfer Reinforcement Learning)\n",
    "%pip install transformers # Biblioteca Hugging Face Transformers\n",
    "%pip install ipywidgets # Biblioteca para widgets interativos no Jupyter Notebook\n",
    "%pip install ipython # Biblioteca IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pré-processamento do Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi realizado o download do arquivo *AmazonTitles-1.3M* e separado da seguinte forma os arquivos:\n",
    "- *trn.json* -> Dataset que será utilizado para o treinamento do modelo.\n",
    "- *tst.json* -> Dataset que será utilizado para avaliar o modelo treinado.\n",
    "- *lbl.json* -> Dataset utilizado para validar as respostas do modelo treinado.\n",
    "\n",
    "Para este Fine Tuning será utilizado a coluna 'title' para o **input** e a coluna 'content' para o **output**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset treinamento**\n",
    "\n",
    "O dataset de treinamento (trn.json) foi pre-processado para retirar os dados vazios que possam existir nas colunas 'title' e 'content', formatado para ficar na forma de prompt alpaca (instrução, entrada, resposta) e separado em 10 partes para que seja possível fazer um treinamento mais rápido.\n",
    "\n",
    "Notebook: [etapa-1-pre-processamento-treino](./etapa-1-pre-processamento-treino.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset teste**\n",
    "\n",
    "O dataset de teste (tst.json) foi pre-processado para retirar os dados vazios que possam existir nas colunas 'title' e 'content', formatado para ficar na forma de prompt alpaca (instrução, entrada, resposta) e, de forma aleatoria, separado 30% do dataset para usar como avaliação no Fine Tuning.\n",
    "\n",
    "Notebook: [etapa-2-pre-processamento-teste](etapa-2-pre-processamento-teste.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fine Tuning**\n",
    "\n",
    "O Fine Tuning foi realizado em cima do Foundation Model **Tiny Llama**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parâmetros**\n",
    "\n",
    "Foi utilizado apenas a parte 1 do dataset para realizar algumas validações relacionadas ao parâmetro do treinamento. Este teste foi mais para achar um equilibrio entre **Tempo**, **Uso de GPU** e **Resultado da Avaliação**.\n",
    "\n",
    "Notebook: [etapa-3-fine-tuning-parametros](./etapa-3-fine-tuning-parametros.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Completo**\n",
    "\n",
    "Utilizando todos os parâmetros que foram validados no notebook acima foi realizado um treinamento completo do modelo com todas as partes do dataset. Para cada parte treinada o modelo foi salvo para uma comparação feita no próximo Notebook.\n",
    "\n",
    "Notebook: [etapa-4-fine-tuning-completo](./etapa-4-fine-tuning-completo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliação**\n",
    "\n",
    "Essa etapa foi criada mais por curiosidade, para saber como fica o desempenho do modelo cada vez que ele é treinado por uma nova parte do dataset.\n",
    "\n",
    "Notebook: [etapa-5-fine-tuning-avaliacao](./etapa-5-fine-tuning-avaliacao.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Validação**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o dataset de validação (lbl.json) é realizado uma validação de como fica a resposta do Foundation Model comparado com o modelo treinado.\n",
    "\n",
    "Notebook: [etapa-6-validacao-modelo](./etapa-6-validacao-modelo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modelo Final**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza o modelo final para gerar novas descrições com o texto de entrada que é digitado pelo usuário.\n",
    "\n",
    "Notebook: [etapa-7-modelo-final](./etapa-7-modelo-final.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
