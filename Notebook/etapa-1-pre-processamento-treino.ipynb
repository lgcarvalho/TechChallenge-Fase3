{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Importando as bibliotecas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Inicializando o Foundation Model***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Foundation Model escolhido para o treinamento ser√° o **unsloth/tinyllama-bnb-4bit** por conta do tamanho e a utiliza√ß√£o da mem√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 256 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/tinyllama-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Pr√©-processamento do dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt**\n",
    "\n",
    "Para estruturar os dados de treinamento vai ser utilizado o Alpaca, com isso vai ser poss√≠vel fornecer ao modelo uma estrutura consistente que vai incluir:\n",
    "- **Instru√ß√£o**\n",
    "- **Input (Contexto adicional)**\n",
    "- **Resposta esperada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fun√ß√µes de apoio**\n",
    "\n",
    "As fun√ß√µes abaixo ser√£o utilizadas para o pre-processamento do dataset, uma fun√ß√£o valida a quantidade de vazios dentro de um campo especifico e a outra vai formatar os dados do dataset para o prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica a quantidade de vazio em um campo espec√≠fico do dataset\n",
    "def contar_campos_vazios(dataset, campo):\n",
    "    qtd_vazio = 0\n",
    "\n",
    "    for example in dataset:\n",
    "        if not example[campo]:\n",
    "            qtd_vazio += 1\n",
    "\n",
    "    return qtd_vazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formata o dataset para o formato esperado pelo modelo\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"title\"]\n",
    "    outputs = examples[\"content\"]\n",
    "    texts = []\n",
    "    \n",
    "    for input, output in zip(inputs, outputs):     \n",
    "        instruction = \"Generate a detailed product description based on the following title:\"\n",
    "        \n",
    "        # Formata o prompt incluindo o token EOS ao final\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formatando o dataset**\n",
    "\n",
    "Para a formata√ß√£o ser√° utilizado as duas fun√ß√µes acima.\n",
    "\n",
    "Inicialmente ser√° validado quantos campos vazios existem na coluna 'content' e na coluna 'title' do dataset, depois ser√° removido esses vazios e finalmente ser√° realizado a formata√ß√£o dos dados e a cria√ß√£o de uma nova coluna chamada 'text' que vai conter o prompt que ser√° utilizado no treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas com content vazio: 749901\n",
      "Linhas com title vazio: 126834\n"
     ]
    }
   ],
   "source": [
    "# Carrega o dataset completo.\n",
    "dataset = load_dataset(\"json\", data_files='./LF-Amazon-1.3M/treino/trn.json', split=\"train\")\n",
    "\n",
    "# Valida a quantidade de linhas com 'content' vazio\n",
    "qtd_vazio = contar_campos_vazios(dataset, 'content')\n",
    "print(f\"Linhas com content vazio: {qtd_vazio}\")\n",
    "\n",
    "# Valida a quantidade de linhas com 'title' vazio\n",
    "qtd_vazio = contar_campos_vazios(dataset, 'title')\n",
    "print(f\"Linhas com title vazio: {qtd_vazio}\")\n",
    "\n",
    "# Filtrar o dataset, removendo linhas com 'title' ou 'content' vazios\n",
    "dataset_processado = dataset.filter(lambda example: example[\"content\"] != \"\" and example[\"title\"] != \"\")\n",
    "\n",
    "# Agora que o dataset est√° limpo, vamos formatar os prompts\n",
    "dataset_formatado = dataset_processado.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Validando quantidade de tokens***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ap√≥s o dataset estar formatado vou realizar uma contagem de tokens para saber, na m√©dia, quantos tokens est√£o sendo usados no meu campo 'text'.\n",
    "\n",
    "Essa valida√ß√£o √© apenas para ter uma ideia de qual o valor de **max_seq_length** eu posso utilizar ao carregar e treinar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para contar tokens\n",
    "def contar_tokens(exemplo):\n",
    "    tokens = tokenizer.encode(exemplo[\"text\"], truncation=False)  # Tokenizar o campo 'text'\n",
    "    return {\"num_tokens\": len(tokens)}  # Retorna o n√∫mero de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©dia de tokens por exemplo: 253.46525647600012\n"
     ]
    }
   ],
   "source": [
    "# Aplicar a fun√ß√£o de contagem de tokens ao dataset formatado\n",
    "dataset_com_tokens = dataset_formatado.map(contar_tokens)\n",
    "\n",
    "# Calcular a m√©dia de tokens por exemplo\n",
    "media_tokens = sum(dataset_com_tokens[\"num_tokens\"]) / len(dataset_com_tokens)\n",
    "print(f\"M√©dia de tokens por exemplo: {media_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Separando o dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar ser√° verificado a quantidade de dados que o dataset possui ap√≥s o pre-processamento e ser√° realizado um **shuffle** nestes dados para depois separar o dataset em 10 partes iguais e para cada parte ser√° salvo um dataset no formato json.\n",
    "\n",
    "Foi utilizado o **shuffle** para que cada parte separado do dataset possua informa√ß√µes de produtos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de dados no dataset: 1390403\n"
     ]
    }
   ],
   "source": [
    "# Validando quantidade de dados no dataset\n",
    "print(f\"Quantidade de dados no dataset: {len(dataset_formatado['text'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uid': ['0385753845', 'B00FXK0XLS', '0967020506', '1285424484', 'B0046TT1NI'], 'title': ['How to Babysit a Grandma', \"Earth's Essentials Organic Fractionated Coconut Oil-16 Oz. Pump Bottle-USP Food Grade\", 'Cold Cash: The Perfect Heist (Northern Mania!)', 'South-Western Federal Taxation 2014: Corporations, Partnerships, Estates &amp; Trusts', 'Set of 3 Black Minicheck Country Homespun Dish Towels'], 'content': [\"PreS-Gr 2&#x2014;In a companion to Reagan's How to Babysit a Grandpa (Knopf, 2012), a young girl heads over to her grandma's house for a sleepover babysitting session-with the child providing clear and humorous instructions to readers on how to care for a grandma. The to-do list contains many choices for Grandma to select from, including a walk to the park, reading, taking photos, playing dress-up, and adding sugary sprinkles to her meal items. The child wisely allows plenty of time for Grandma to look at the pages while reading a book, peek at the stars, and choose the best spot to sleep. Any grown-up who has calmly been the object of a child's flights of fancy will chuckle at the scenarios, as Grandma, never mugging or rolling her eyes, participates fully and patiently in all of her granddaughter's ideas. The full-color digital art is bright, and sharp-eyed children will delight in the details, including the silly antics of Grandma's dog. While this book breaks no new ground, the charm of its premise and the clear bond between the generations will have kids and grandparents giggling together.&#x2014;Marge Loch-Wouters, La Crosse Public Library, WI\", 'This is the finest massage oil / carrier oil on the market. Our Fractionated Coconut Oil has been refined through a chemical free steam process to make it clear, stable, and odor free. This oil absorbs rapidly into the skin, making it the ultimate luxurious massage oil.Our Fractionated Coconut Oil contains absolutely no additional or hidden ingredients whatsoever.  It is 100% pure Fractionated Coconut Oil and nothing else.  We sell the highest obtainable food grade available and we purposely avoid the lesser grades because they do contain \"fillers\" and other non-Coconut oils.  Our F.C.O. contains no preservatives or contaminants as well, and is non GMO.  We  laboratory test each lot of our oils for pesticides, heavy metals, and organic solvents and each lot is certified to contain no detectable levels of any contaminants or microbiologicals.  Fractionated Coconut Oil is naturally a very stable oil, though we do recommend that you store the bottle out of sunlight at 65-75 degrees Fahrenheit in a dry and odor free environment to preserve it\\'s 24 month shelf life.', 'Jerry Harju\\'s new \"Cold Cash\" may be billed as a mystery, but it could just as easily be in the humor section.  The suspenseful tale will leave you laughing out loud.  We recommend reading every hilarious word of this gem.  --THE GREEN BAY PRESS GAZETTE, 9 June, 1999', \"Dr. William H. Hoffman, Jr., earned B.A. and J.D. degrees from the University of Michigan and M.B.A. and Ph.D. degrees from The University of Texas. He is a licensed CPA and attorney in Texas. His teaching experience includes The University of Texas (1957-1961), Louisiana State University (1961-1967), and the University of Houston (1967-1999). Dr. Hoffman has addressed many tax institutes and conferences and has published extensively in academic and professional journals. His articles appear in THE JOURNAL OF TAXATION, THE TAX ADVISER, TAXES ? THE TAX MAGAZINE, THE JOURNAL OF ACCOUNTANCY, THE ACCOUNTING REVIEW, and TAXATION FOR ACCOUNTANTS.William A. Raabe, Ph.D., CPA, teaches graduate tax courses at the Fisher College of Business at The Ohio State University and at the Capital University (OH) Law School. He is a leader among business school tax faculty in incorporating developments in technology into curricula for the educational development of tax professionals.  Dr. Raabe's teaching and research interests focus on multijurisdictional taxation and financial planning, and he is recognized as the leader among business school academics in the fields of state and local income, sales, and property taxation. Dr. Raabe is the author or editor of approximately twenty books, including this text, SCHEDULE M-3 COMPLIANCE, and the MULTISTATE CORPORATE TAX GUIDE. He has received university-wide recognition as the winner of the AMOCO Foundation Award for Teaching Excellence, and the Wisconsin Institute of CPAs named him the Educator of the Year.Dr. James E. Smith is the John S. Quinn Professor of Accounting at the College of William and Mary. He has been a member of the accounting faculty for more than 30 years. He received his Ph.D. from the University of Arizona. Dr. Smith has served as a discussion leader for Continuing Professional Education programs for the American Institute of Certified Public Accountants (AICPA), Federal Tax Workshops, and various state CPA societies. He has conducted programs in more than 40 states for about 25,000 CPAs. He has been the recipient of the AICPA's Outstanding Discussion Leader Award and the American Taxation Association/Arthur Andersen Teaching Innovation Award. Among his other awards are the Virginia Society of CPAs' Outstanding Accounting Educator Award and the James Madison University's Outstanding Accounting Educator Award. He was the president of the Administrators of Accounting Programs Group (AAPG) in 1991-1992. He was the faculty adviser for the William and Mary teams that received first place in the Andersen Tax Challenge for five years and in the Deloitte Tax Case Study Competition for five years.David M. Maloney, Ph.D., CPA, is the Carman G. Blough Professor of Accounting at the University of Virginia's McIntire School of Commerce. He completed his undergraduate work at the University of Richmond and his graduate work at the University of Illinois at Urbana-Champaign. Since joining the Virginia faculty in January 1984, Professor Maloney has taught federal taxation in the graduate and undergraduate programs and has received major research grants from the Ernst & Young and KPMG Foundations. In addition, his work has been published in numerous professional journals, including THE JOURNAL OF TAXATION, THE TAX ADVISOR, TAX NOTES, CORPORATE TAXATION, ACCOUNTING HORIZONS, JOURNAL OF TAXATION OF INVESTMENTS, and JOURNAL OF ACCOUNTANCY. He is a member of several professional organizations, including the American Accounting Association and the American Taxation Association.--This text refers to an alternateHardcoveredition.\", 'Set of 3 black minicheck kitchen towels are made of soft homespun fabric'], 'target_ind': [[4714, 6240, 7087, 7089, 7091, 7097, 7100, 7946, 9939, 9941, 9954, 11204, 11269, 14704, 17422, 17613, 39897, 40299, 40346, 41293, 41548, 41833, 43213, 43517, 43939, 43943, 43955, 45457, 45692, 45821, 45825, 45827, 48058, 48063, 48068, 48073, 48079, 48081, 48093, 48096, 51606, 51632, 51696, 52045, 52135, 52273, 52317, 52623, 52820, 52825, 52844, 52845, 52846, 53139, 53140, 53143, 53145, 53147, 53148, 53149, 53161, 53170, 60970, 60971, 61596, 61682, 61688, 63488, 78880, 82816, 83316, 83322, 83326, 109460, 124563, 125002, 211870, 211871, 295771, 335046, 339849], [6839, 6866, 6874, 6881, 6887, 6888, 6890, 6892, 6895, 6907, 6908, 6911, 6912, 6914, 6917, 109113, 109116, 110189, 126440, 132261, 149763, 182276, 182282, 182304, 247044, 284983, 285983, 287359, 344526, 357941, 358039, 366080, 397226, 397229, 401232, 406607, 406616, 406619, 406623, 408150, 410862, 410864, 411622, 419925, 427301, 429957, 434556, 447264, 447485, 490861, 505935, 515822, 515974, 516903, 517841, 517843, 522813, 522819, 523392, 523400, 523414, 529025, 530533, 530534, 530535, 530541, 530550, 536476, 538703, 538742, 539298, 539301, 539302, 539631, 567345, 578068, 600168, 600172, 606923, 798378, 1083611], [529491], [16037, 25425, 31851, 33395, 35456, 35882, 35924, 36290, 36292, 36293, 47298, 70213, 70216, 70249, 76761, 81989, 89369, 93647, 99743, 140243, 140249, 140252, 140298, 140302, 140310, 140311, 140316, 140317, 140319, 140935, 144265, 145111, 145112, 145113, 145114, 145117, 145511, 145552, 145555, 145780, 145787, 148392, 150024, 150037, 151800, 155356, 157563, 158321, 159409, 159612, 161568, 167320, 168260, 168625, 169711, 171907, 172412, 174083, 174297, 174448, 174496, 174497, 175047, 176204, 176246, 177627, 179945, 195802, 302767], [1190951]], 'target_rel': [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0]], 'text': [\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nHow to Babysit a Grandma\\n\\n### Response:\\nPreS-Gr 2&#x2014;In a companion to Reagan's How to Babysit a Grandpa (Knopf, 2012), a young girl heads over to her grandma's house for a sleepover babysitting session-with the child providing clear and humorous instructions to readers on how to care for a grandma. The to-do list contains many choices for Grandma to select from, including a walk to the park, reading, taking photos, playing dress-up, and adding sugary sprinkles to her meal items. The child wisely allows plenty of time for Grandma to look at the pages while reading a book, peek at the stars, and choose the best spot to sleep. Any grown-up who has calmly been the object of a child's flights of fancy will chuckle at the scenarios, as Grandma, never mugging or rolling her eyes, participates fully and patiently in all of her granddaughter's ideas. The full-color digital art is bright, and sharp-eyed children will delight in the details, including the silly antics of Grandma's dog. While this book breaks no new ground, the charm of its premise and the clear bond between the generations will have kids and grandparents giggling together.&#x2014;Marge Loch-Wouters, La Crosse Public Library, WI</s>\", 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nEarth\\'s Essentials Organic Fractionated Coconut Oil-16 Oz. Pump Bottle-USP Food Grade\\n\\n### Response:\\nThis is the finest massage oil / carrier oil on the market. Our Fractionated Coconut Oil has been refined through a chemical free steam process to make it clear, stable, and odor free. This oil absorbs rapidly into the skin, making it the ultimate luxurious massage oil.Our Fractionated Coconut Oil contains absolutely no additional or hidden ingredients whatsoever.  It is 100% pure Fractionated Coconut Oil and nothing else.  We sell the highest obtainable food grade available and we purposely avoid the lesser grades because they do contain \"fillers\" and other non-Coconut oils.  Our F.C.O. contains no preservatives or contaminants as well, and is non GMO.  We  laboratory test each lot of our oils for pesticides, heavy metals, and organic solvents and each lot is certified to contain no detectable levels of any contaminants or microbiologicals.  Fractionated Coconut Oil is naturally a very stable oil, though we do recommend that you store the bottle out of sunlight at 65-75 degrees Fahrenheit in a dry and odor free environment to preserve it\\'s 24 month shelf life.</s>', 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nCold Cash: The Perfect Heist (Northern Mania!)\\n\\n### Response:\\nJerry Harju\\'s new \"Cold Cash\" may be billed as a mystery, but it could just as easily be in the humor section.  The suspenseful tale will leave you laughing out loud.  We recommend reading every hilarious word of this gem.  --THE GREEN BAY PRESS GAZETTE, 9 June, 1999</s>', \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nSouth-Western Federal Taxation 2014: Corporations, Partnerships, Estates &amp; Trusts\\n\\n### Response:\\nDr. William H. Hoffman, Jr., earned B.A. and J.D. degrees from the University of Michigan and M.B.A. and Ph.D. degrees from The University of Texas. He is a licensed CPA and attorney in Texas. His teaching experience includes The University of Texas (1957-1961), Louisiana State University (1961-1967), and the University of Houston (1967-1999). Dr. Hoffman has addressed many tax institutes and conferences and has published extensively in academic and professional journals. His articles appear in THE JOURNAL OF TAXATION, THE TAX ADVISER, TAXES ? THE TAX MAGAZINE, THE JOURNAL OF ACCOUNTANCY, THE ACCOUNTING REVIEW, and TAXATION FOR ACCOUNTANTS.William A. Raabe, Ph.D., CPA, teaches graduate tax courses at the Fisher College of Business at The Ohio State University and at the Capital University (OH) Law School. He is a leader among business school tax faculty in incorporating developments in technology into curricula for the educational development of tax professionals.  Dr. Raabe's teaching and research interests focus on multijurisdictional taxation and financial planning, and he is recognized as the leader among business school academics in the fields of state and local income, sales, and property taxation. Dr. Raabe is the author or editor of approximately twenty books, including this text, SCHEDULE M-3 COMPLIANCE, and the MULTISTATE CORPORATE TAX GUIDE. He has received university-wide recognition as the winner of the AMOCO Foundation Award for Teaching Excellence, and the Wisconsin Institute of CPAs named him the Educator of the Year.Dr. James E. Smith is the John S. Quinn Professor of Accounting at the College of William and Mary. He has been a member of the accounting faculty for more than 30 years. He received his Ph.D. from the University of Arizona. Dr. Smith has served as a discussion leader for Continuing Professional Education programs for the American Institute of Certified Public Accountants (AICPA), Federal Tax Workshops, and various state CPA societies. He has conducted programs in more than 40 states for about 25,000 CPAs. He has been the recipient of the AICPA's Outstanding Discussion Leader Award and the American Taxation Association/Arthur Andersen Teaching Innovation Award. Among his other awards are the Virginia Society of CPAs' Outstanding Accounting Educator Award and the James Madison University's Outstanding Accounting Educator Award. He was the president of the Administrators of Accounting Programs Group (AAPG) in 1991-1992. He was the faculty adviser for the William and Mary teams that received first place in the Andersen Tax Challenge for five years and in the Deloitte Tax Case Study Competition for five years.David M. Maloney, Ph.D., CPA, is the Carman G. Blough Professor of Accounting at the University of Virginia's McIntire School of Commerce. He completed his undergraduate work at the University of Richmond and his graduate work at the University of Illinois at Urbana-Champaign. Since joining the Virginia faculty in January 1984, Professor Maloney has taught federal taxation in the graduate and undergraduate programs and has received major research grants from the Ernst & Young and KPMG Foundations. In addition, his work has been published in numerous professional journals, including THE JOURNAL OF TAXATION, THE TAX ADVISOR, TAX NOTES, CORPORATE TAXATION, ACCOUNTING HORIZONS, JOURNAL OF TAXATION OF INVESTMENTS, and JOURNAL OF ACCOUNTANCY. He is a member of several professional organizations, including the American Accounting Association and the American Taxation Association.--This text refers to an alternateHardcoveredition.</s>\", 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate a detailed product description based on the following title:\\n\\n### Input:\\nSet of 3 Black Minicheck Country Homespun Dish Towels\\n\\n### Response:\\nSet of 3 black minicheck kitchen towels are made of soft homespun fabric</s>']}\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a randomiza√ß√£o no dataset\n",
    "dataset_randomizado = dataset_formatado.shuffle(seed=42)\n",
    "\n",
    "# Verificar os primeiros exemplos para garantir que o shuffle foi aplicado\n",
    "print(dataset_randomizado[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 1: 139041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ec950395434167b6d160744e1ded74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 2: 139041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7065e95a25b241a4b8dd8554f8f84d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 3: 139041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf805af21d9417ebffa979062d27034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 4: 139040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae598ffd4d664afba934f33c01456520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 5: 139040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df556cb189c94931bbb80e3d3679b54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 6: 139040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3099811fa14121991b6ffe2770b08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 7: 139040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1ca18ce36a48fe92f051e59f76b13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 8: 139040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71af501f578b48e797dc30de76750462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 9: 139040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4f07c419eb4667a8848052d4b73fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da parte 10: 139040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddf146740d1456a8c18eca07fb5057c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/140 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dividir o dataset em 10 partes iguais usando 'shard'\n",
    "dataset_divido = [dataset_randomizado.shard(num_shards=10, index=i) for i in range(10)]\n",
    "\n",
    "# Salvar as partes\n",
    "for i, ds in enumerate(dataset_divido):\n",
    "    print(f\"Tamanho da parte {i+1}: {len(ds)}\")\n",
    "    \n",
    "    ds.to_json(f\"./LF-Amazon-1.3M/treino/trn_formatado_parte_{i+1}.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
