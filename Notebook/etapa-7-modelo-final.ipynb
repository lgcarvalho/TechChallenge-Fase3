{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Importando as bibliotecas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import ipywidgets as widgets\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import TextStreamer\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Inicializando o Modelo***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt**\n",
    "\n",
    "Para estruturar os dados de entrada do usuário vai ser utilizado o Alpaca, com isso vai ser possível fornecer ao modelo uma estrutura consistente que vai incluir:\n",
    "- **Instrução**\n",
    "- **Input (Contexto adicional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função de inicialização**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recebe como parâmetro o input do usuário e o output do modelo:\n",
    "\n",
    "**1.** Limpeza de memória.\n",
    "- É realizado a limpeza na memória para o modelo que será carregado.\n",
    "\n",
    "**2.** Inicialização do modelo.\n",
    "- Inícia o modelo treinado.\n",
    "- Habilita o modo de inferência\n",
    "\n",
    "**3.** Criação do input e do streamer.\n",
    "- Realiza a formatação do *alpaca_prompt* utilizando o parâmetro de entrada.\n",
    "\n",
    "**4.** Gerar o texto\n",
    "- Realiza a geração do novo texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia o modelo e realiza a geração de texto\n",
    "def iniciar_modelo(input, output):\n",
    "    with output:\n",
    "        # Limpar o output anterior\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Limpar a memória da GPU\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        max_seq_length = 256 # Choose any! We auto support RoPE Scaling internally!\n",
    "        dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "        load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "        # Inicializa o modelo e o tokenizer\n",
    "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name = './model/lora_model_final',\n",
    "            max_seq_length = max_seq_length,\n",
    "            dtype = dtype,\n",
    "            load_in_4bit = load_in_4bit,\n",
    "        )\n",
    "        \n",
    "        # Habilita o modo de inferência rápida\n",
    "        FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "        \n",
    "        # Instrução para o modelo\n",
    "        instruction = 'Generate a detailed product description based on the following title:'\n",
    "        \n",
    "        # Cria o input para o modelo\n",
    "        inputs = tokenizer(\n",
    "            [\n",
    "                alpaca_prompt.format(instruction, input, \"\")\n",
    "            ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "        # Cria o streamer de texto\n",
    "        text_streamer = TextStreamer(tokenizer)\n",
    "        \n",
    "        # Gera o texto\n",
    "        _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entrada Usuário**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O usuário pode digitar o nome do produto para que o modelo possa gerar uma descrição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f998fec2ce144af88097de5c3ac55562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='PRODUCT NAME:', layout=Layout(width='30%'), placeholder='TYPE HERE...', style=Text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7090b1edfa0b4ec1a91c30b05d0b189d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='SEARCH DESCRIPTION', layout=Layout(width='30%'), style=ButtonStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb6681948cc43078a297ab057dcd6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando uma caixa de texto\n",
    "texto = widgets.Text(\n",
    "    description=\"PRODUCT NAME:\",\n",
    "    placeholder=\"TYPE HERE...\",\n",
    "    layout=widgets.Layout(width='30%'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "botao = widgets.Button(\n",
    "    description=\"SEARCH DESCRIPTION\",\n",
    "    button_style=\"primary\",\n",
    "    layout=widgets.Layout(width='30%')\n",
    ")\n",
    "\n",
    "output = widgets.Output(layout=widgets.Layout(width='100%'))\n",
    "\n",
    "botao.on_click(lambda b: iniciar_modelo(texto.value, output))\n",
    "\n",
    "# Exibindo a caixa de texto\n",
    "display(texto, botao, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
